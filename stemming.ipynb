{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming refers to a process of reducing a word to its word stem that affixes suffixes and prefixes or to the roots of words known as lemma. Stemming is important in natural language understanding (NLU) and Natural Languaga Processing(NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegexpStemmer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK has RegexpStemmer class with the help of which we can easily implement Regulat Expression Stemmer Algorithms. It basically takes a singular regular expression and removes the suffix or prefix that matches the expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stemming is generally used for classification problem. For eg: We have to classify comments of a product as postive or negative. \n",
    "###### The comments me have similar words like 'eating', 'eaten' (for restaurants) and we may need to extract the core word removing the suffixes or prefixes. For this we use stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ----> eat\n",
      "eaten ----> eaten\n",
      "eat ----> eat\n",
      "writing ----> write\n",
      "writes ----> write\n",
      "programming ----> program\n",
      "programs ----> program\n",
      "finally ----> final\n",
      "finalized ----> final\n",
      "history ----> histori\n"
     ]
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"eating\", \"eaten\", \"eat\" , \"writing\", \"writes\", \"programming\", \"programs\", \"finally\",\"finalized\",\"history\"]\n",
    "for word in words :\n",
    "    print ( word+\" ----> \"+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notice in the above example how history changes to 'histori'. This is a major disadvantage of stemming. In stemming the form of some words can change so drastically that the complete meaning of that word is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example for the same \n",
    "stemmer.stem('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegexpStemmer Class\n",
    "##### NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer Algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Regexp Stemmer Class\n",
    "\n",
    "# The Regexp stemmer class takes two paremeters. \n",
    "# One is the regular expression that matches the morphological affixes. Any string that matches it will be stemmed.\n",
    "# The second parameter is the minimum length of the string to stem.\n",
    "\n",
    "from nltk.stem import RegexpStemmer\n",
    "regStemmer = RegexpStemmer('ing$|s$|e$|able$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regStemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regStemmer.stem('ingeat') # The output will be same because in regular expression, we mentioned to stem words which only ends with 'ing'.\n",
    "\n",
    "# If we want to remove 'ing' from the starting, we can use '$ing' in the regular expression.\n",
    "# Or we can simply use 'ing'. This will remove ing from any place be it suffix or prefix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regStemmer2 =  RegexpStemmer('ing',min=4)\n",
    "\n",
    "regStemmer2.stem('ingeat') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer\n",
    "##### Snowball is again another stemming tecnique but it is better than Porter Stemmer because it fixes the words which were being messed up by the porter stemmer. Snowball Stemmer tecnique was developed after porter stemmer issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snowballStemmer = SnowballStemmer('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('fairly'),stemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballStemmer.stem('fairly'),snowballStemmer.stem('sportingly') # Correct output generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('goe', 'histori')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Issues with stemming :\n",
    "stemmer.stem('goes'),stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('goe', 'histori')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballStemmer.stem('goes'),snowballStemmer.stem('history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notice how both the tecniques generate incorrect results for some words. Therfore to solve this issue, we use lemmitization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
